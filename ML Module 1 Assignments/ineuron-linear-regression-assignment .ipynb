{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the linear regression model using scikit learn in boston data to predict 'Price' based on other dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "bos = pd.DataFrame(boston.data)\n",
    "bos.columns=boston.feature_names\n",
    "bos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price=pd.DataFrame(boston.target, columns = ['MEDV'])\n",
    "df = bos.join(price)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.figure(figsize = (12,6))\\nsns.heatmap(df.corr(),annot = True)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"plt.figure(figsize = (12,6))\n",
    "sns.heatmap(df.corr(),annot = True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337, 13)\n",
      "(169, 13)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "#train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS Stats.api model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>6.72e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:48:58</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   36.4595</td> <td>    5.103</td> <td>    7.144</td> <td> 0.000</td> <td>   26.432</td> <td>   46.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>      <td>   -0.1080</td> <td>    0.033</td> <td>   -3.287</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>        <td>    0.0464</td> <td>    0.014</td> <td>    3.382</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>     <td>    0.0206</td> <td>    0.061</td> <td>    0.334</td> <td> 0.738</td> <td>   -0.100</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>      <td>    2.6867</td> <td>    0.862</td> <td>    3.118</td> <td> 0.002</td> <td>    0.994</td> <td>    4.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>       <td>  -17.7666</td> <td>    3.820</td> <td>   -4.651</td> <td> 0.000</td> <td>  -25.272</td> <td>  -10.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>        <td>    3.8099</td> <td>    0.418</td> <td>    9.116</td> <td> 0.000</td> <td>    2.989</td> <td>    4.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>       <td>    0.0007</td> <td>    0.013</td> <td>    0.052</td> <td> 0.958</td> <td>   -0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>       <td>   -1.4756</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.867</td> <td>   -1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>       <td>    0.3060</td> <td>    0.066</td> <td>    4.613</td> <td> 0.000</td> <td>    0.176</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>       <td>   -0.0123</td> <td>    0.004</td> <td>   -3.280</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th>   <td>   -0.9527</td> <td>    0.131</td> <td>   -7.283</td> <td> 0.000</td> <td>   -1.210</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>         <td>    0.0093</td> <td>    0.003</td> <td>    3.467</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>     <td>   -0.5248</td> <td>    0.051</td> <td>  -10.347</td> <td> 0.000</td> <td>   -0.624</td> <td>   -0.425</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.041</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 783.126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>8.84e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.281</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   MEDV   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Sat, 06 Feb 2021   Prob (F-statistic):          6.72e-135\n",
       "Time:                        22:48:58   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     36.4595      5.103      7.144      0.000      26.432      46.487\n",
       "CRIM          -0.1080      0.033     -3.287      0.001      -0.173      -0.043\n",
       "ZN             0.0464      0.014      3.382      0.001       0.019       0.073\n",
       "INDUS          0.0206      0.061      0.334      0.738      -0.100       0.141\n",
       "CHAS           2.6867      0.862      3.118      0.002       0.994       4.380\n",
       "NOX          -17.7666      3.820     -4.651      0.000     -25.272     -10.262\n",
       "RM             3.8099      0.418      9.116      0.000       2.989       4.631\n",
       "AGE            0.0007      0.013      0.052      0.958      -0.025       0.027\n",
       "DIS           -1.4756      0.199     -7.398      0.000      -1.867      -1.084\n",
       "RAD            0.3060      0.066      4.613      0.000       0.176       0.436\n",
       "TAX           -0.0123      0.004     -3.280      0.001      -0.020      -0.005\n",
       "PTRATIO       -0.9527      0.131     -7.283      0.000      -1.210      -0.696\n",
       "B              0.0093      0.003      3.467      0.001       0.004       0.015\n",
       "LSTAT         -0.5248      0.051    -10.347      0.000      -0.624      -0.425\n",
       "==============================================================================\n",
       "Omnibus:                      178.041   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126\n",
       "Skew:                           1.521   Prob(JB):                    8.84e-171\n",
       "Kurtosis:                       8.281   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "ols_model = smf.ols(formula='MEDV ~ CRIM+ZN+INDUS+CHAS+NOX+RM+AGE+DIS+RAD+TAX+PTRATIO+B+LSTAT', data=df).fit()\n",
    "ols_model.conf_int()\n",
    "ols_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the OLS statsmodels summary, the p valuue, R value and F-value has been calculated. Considering the p-value=0.05, eliminate features which have p value more than 0.05. \"INDUS\", \"AGE\" are the only features with high p-values. So, these features are not significant in determining the target value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.455621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>-0.200469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.412995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.603800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.053929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.590879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.613808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.602339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.496996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.625505</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.488676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.582764</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.543993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.374044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "CRIM     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
       "ZN      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
       "INDUS    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
       "CHAS    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
       "NOX      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
       "RM      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
       "AGE      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
       "DIS     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
       "RAD      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
       "TAX      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
       "PTRATIO  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
       "B       -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
       "LSTAT    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
       "\n",
       "              DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "CRIM    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621  \n",
       "ZN       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  \n",
       "INDUS   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800  \n",
       "CHAS    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  \n",
       "NOX     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879  \n",
       "RM       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  \n",
       "AGE     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339  \n",
       "DIS      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  \n",
       "RAD     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676  \n",
       "TAX     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993  \n",
       "PTRATIO -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044  \n",
       "B        0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  \n",
       "LSTAT   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(labels=[\"AGE\", \"INDUS\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.735</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   128.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>5.54e-137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:48:58</td>     <th>  Log-Likelihood:    </th> <td> -1498.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3022.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   494</td>      <th>  BIC:               </th> <td>   3072.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   36.3411</td> <td>    5.067</td> <td>    7.171</td> <td> 0.000</td> <td>   26.385</td> <td>   46.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>      <td>   -0.1084</td> <td>    0.033</td> <td>   -3.307</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>        <td>    0.0458</td> <td>    0.014</td> <td>    3.390</td> <td> 0.001</td> <td>    0.019</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>      <td>    2.7187</td> <td>    0.854</td> <td>    3.183</td> <td> 0.002</td> <td>    1.040</td> <td>    4.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>       <td>  -17.3760</td> <td>    3.535</td> <td>   -4.915</td> <td> 0.000</td> <td>  -24.322</td> <td>  -10.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>        <td>    3.8016</td> <td>    0.406</td> <td>    9.356</td> <td> 0.000</td> <td>    3.003</td> <td>    4.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>       <td>    0.2996</td> <td>    0.063</td> <td>    4.726</td> <td> 0.000</td> <td>    0.175</td> <td>    0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>       <td>   -1.4927</td> <td>    0.186</td> <td>   -8.037</td> <td> 0.000</td> <td>   -1.858</td> <td>   -1.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>       <td>   -0.0118</td> <td>    0.003</td> <td>   -3.493</td> <td> 0.001</td> <td>   -0.018</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th>   <td>   -0.9465</td> <td>    0.129</td> <td>   -7.334</td> <td> 0.000</td> <td>   -1.200</td> <td>   -0.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>         <td>    0.0093</td> <td>    0.003</td> <td>    3.475</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>     <td>   -0.5226</td> <td>    0.047</td> <td>  -11.019</td> <td> 0.000</td> <td>   -0.616</td> <td>   -0.429</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.430</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 787.785</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.523</td>  <th>  Prob(JB):          </th> <td>8.60e-172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.300</td>  <th>  Cond. No.          </th> <td>1.47e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.47e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   MEDV   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.735\n",
       "Method:                 Least Squares   F-statistic:                     128.2\n",
       "Date:                Sat, 06 Feb 2021   Prob (F-statistic):          5.54e-137\n",
       "Time:                        22:48:58   Log-Likelihood:                -1498.9\n",
       "No. Observations:                 506   AIC:                             3022.\n",
       "Df Residuals:                     494   BIC:                             3072.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     36.3411      5.067      7.171      0.000      26.385      46.298\n",
       "CRIM          -0.1084      0.033     -3.307      0.001      -0.173      -0.044\n",
       "ZN             0.0458      0.014      3.390      0.001       0.019       0.072\n",
       "CHAS           2.7187      0.854      3.183      0.002       1.040       4.397\n",
       "NOX          -17.3760      3.535     -4.915      0.000     -24.322     -10.430\n",
       "RM             3.8016      0.406      9.356      0.000       3.003       4.600\n",
       "RAD            0.2996      0.063      4.726      0.000       0.175       0.424\n",
       "DIS           -1.4927      0.186     -8.037      0.000      -1.858      -1.128\n",
       "TAX           -0.0118      0.003     -3.493      0.001      -0.018      -0.005\n",
       "PTRATIO       -0.9465      0.129     -7.334      0.000      -1.200      -0.693\n",
       "B              0.0093      0.003      3.475      0.001       0.004       0.015\n",
       "LSTAT         -0.5226      0.047    -11.019      0.000      -0.616      -0.429\n",
       "==============================================================================\n",
       "Omnibus:                      178.430   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              787.785\n",
       "Skew:                           1.523   Prob(JB):                    8.60e-172\n",
       "Kurtosis:                       8.300   Cond. No.                     1.47e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.47e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_model = smf.ols(formula='MEDV ~ CRIM+ZN+CHAS+NOX+RM+RAD+DIS+TAX+PTRATIO+B+LSTAT', data=df).fit()\n",
    "ols_model.conf_int()\n",
    "ols_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337, 11)\n",
      "(169, 11)\n"
     ]
    }
   ],
   "source": [
    "X=X.values\n",
    "y=y.values\n",
    "\n",
    "#train-test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24.71 22.6 ]\n",
      " [24.21 50.  ]\n",
      " [29.49 23.  ]\n",
      " [12.08  8.3 ]\n",
      " [21.19 21.2 ]\n",
      " [19.1  19.9 ]\n",
      " [20.52 20.6 ]\n",
      " [21.14 18.7 ]\n",
      " [19.   16.1 ]\n",
      " [20.72 18.6 ]\n",
      " [ 5.93  8.8 ]\n",
      " [17.12 17.2 ]\n",
      " [17.   14.9 ]\n",
      " [ 5.34 10.5 ]\n",
      " [40.44 50.  ]\n",
      " [32.34 29.  ]\n",
      " [22.53 23.  ]\n",
      " [36.82 33.3 ]\n",
      " [30.99 29.4 ]\n",
      " [23.09 21.  ]\n",
      " [24.65 23.8 ]\n",
      " [24.81 19.1 ]\n",
      " [20.69 20.4 ]\n",
      " [30.48 29.1 ]\n",
      " [22.18 19.3 ]\n",
      " [11.29 23.1 ]\n",
      " [17.43 19.6 ]\n",
      " [18.14 19.4 ]\n",
      " [35.68 38.7 ]\n",
      " [20.88 18.7 ]\n",
      " [18.31 14.6 ]\n",
      " [17.6  20.  ]\n",
      " [19.56 20.5 ]\n",
      " [23.82 20.1 ]\n",
      " [29.33 23.6 ]\n",
      " [19.41 16.8 ]\n",
      " [10.81  5.6 ]\n",
      " [25.23 50.  ]\n",
      " [18.27 14.5 ]\n",
      " [15.48 13.3 ]\n",
      " [25.89 23.9 ]\n",
      " [20.47 20.  ]\n",
      " [22.05 19.8 ]\n",
      " [15.75 13.8 ]\n",
      " [22.58 16.5 ]\n",
      " [25.02 21.6 ]\n",
      " [19.55 20.3 ]\n",
      " [22.75 17.  ]\n",
      " [ 9.22 11.8 ]\n",
      " [24.36 27.5 ]\n",
      " [21.26 15.6 ]\n",
      " [16.98 23.1 ]\n",
      " [24.54 24.3 ]\n",
      " [29.19 42.8 ]\n",
      " [13.46 15.6 ]\n",
      " [21.2  21.7 ]\n",
      " [20.38 17.1 ]\n",
      " [14.85 17.2 ]\n",
      " [15.4  15.  ]\n",
      " [22.11 21.7 ]\n",
      " [17.01 18.6 ]\n",
      " [21.3  21.  ]\n",
      " [32.87 33.1 ]\n",
      " [31.27 31.5 ]\n",
      " [17.71 20.1 ]\n",
      " [33.04 29.8 ]\n",
      " [18.53 15.2 ]\n",
      " [19.06 15.  ]\n",
      " [19.5  27.5 ]\n",
      " [22.68 22.6 ]\n",
      " [22.96 20.  ]\n",
      " [23.95 21.4 ]\n",
      " [30.83 23.5 ]\n",
      " [28.69 31.2 ]\n",
      " [26.09 23.7 ]\n",
      " [ 4.75  7.4 ]\n",
      " [36.8  48.3 ]\n",
      " [23.54 24.4 ]\n",
      " [27.38 22.6 ]\n",
      " [19.15 18.3 ]\n",
      " [28.5  23.3 ]\n",
      " [19.04 17.1 ]\n",
      " [19.44 27.9 ]\n",
      " [38.03 44.8 ]\n",
      " [39.38 50.  ]\n",
      " [23.43 23.  ]\n",
      " [25.   21.4 ]\n",
      " [16.76 10.2 ]\n",
      " [25.96 23.3 ]\n",
      " [16.48 23.2 ]\n",
      " [15.49 18.9 ]\n",
      " [13.24 13.4 ]\n",
      " [24.38 21.9 ]\n",
      " [31.13 24.8 ]\n",
      " [22.25 11.9 ]\n",
      " [19.73 24.3 ]\n",
      " [ 0.11 13.8 ]\n",
      " [25.12 24.7 ]\n",
      " [16.   14.1 ]\n",
      " [17.5  18.7 ]\n",
      " [25.15 28.1 ]\n",
      " [22.47 19.8 ]\n",
      " [32.86 26.7 ]\n",
      " [21.68 21.7 ]\n",
      " [27.24 22.  ]\n",
      " [23.25 22.9 ]\n",
      " [ 6.87 10.4 ]\n",
      " [15.22 21.9 ]\n",
      " [22.28 20.6 ]\n",
      " [29.06 26.4 ]\n",
      " [33.6  41.3 ]\n",
      " [13.18 17.2 ]\n",
      " [19.66 27.1 ]\n",
      " [20.77 20.4 ]\n",
      " [11.71 16.5 ]\n",
      " [23.24 24.4 ]\n",
      " [ 4.97  8.4 ]\n",
      " [19.77 23.  ]\n",
      " [ 9.14  9.7 ]\n",
      " [44.95 50.  ]\n",
      " [30.72 30.5 ]\n",
      " [12.26 12.3 ]\n",
      " [17.19 19.4 ]\n",
      " [21.33 21.2 ]\n",
      " [23.66 20.3 ]\n",
      " [20.26 18.8 ]\n",
      " [35.33 33.4 ]\n",
      " [13.15 18.5 ]\n",
      " [20.72 19.6 ]\n",
      " [35.37 33.2 ]\n",
      " [19.35 13.1 ]\n",
      " [13.53  7.5 ]\n",
      " [13.92 13.6 ]\n",
      " [23.26 17.4 ]\n",
      " [14.69  8.4 ]\n",
      " [30.95 35.4 ]\n",
      " [25.32 24.  ]\n",
      " [14.81 13.4 ]\n",
      " [23.7  26.2 ]\n",
      " [ 9.7   7.2 ]\n",
      " [14.73 13.1 ]\n",
      " [20.68 24.5 ]\n",
      " [32.95 37.2 ]\n",
      " [27.65 25.  ]\n",
      " [25.51 24.1 ]\n",
      " [15.26 16.6 ]\n",
      " [31.04 32.9 ]\n",
      " [27.68 36.2 ]\n",
      " [14.35 11.  ]\n",
      " [ 7.2   7.2 ]\n",
      " [28.58 22.8 ]\n",
      " [25.15 28.7 ]\n",
      " [ 3.84 14.4 ]\n",
      " [28.47 24.4 ]\n",
      " [16.93 18.1 ]\n",
      " [29.69 22.5 ]\n",
      " [20.24 20.5 ]\n",
      " [15.51 15.2 ]\n",
      " [17.47 17.4 ]\n",
      " [12.38 13.6 ]\n",
      " [ 9.09  8.7 ]\n",
      " [19.05 18.2 ]\n",
      " [34.49 35.4 ]\n",
      " [33.09 31.7 ]\n",
      " [22.96 33.  ]\n",
      " [19.09 22.2 ]\n",
      " [22.7  20.4 ]\n",
      " [26.88 23.9 ]\n",
      " [21.83 25.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE is 26.203377464160234\n",
      "THe RMSE is 5.118923467308359\n",
      "The model R2 score for training set is 0.7679351006196389\n",
      "The model adjusted R2 score for training set is 0.7600805963329189\n",
      "The model R2 score for test set is 0.671409524468376\n",
      "The model adjusted R2 score for test set is 0.6483872618515106\n",
      "Model intercept is 41.29800135647996\n",
      "Model coefficients are [-1.17e-01  4.89e-02  2.50e+00 -1.78e+01  3.60e+00 -1.54e+00  2.53e-01\n",
      " -1.09e-02 -1.05e+00  5.93e-03 -5.31e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse=mean_squared_error(y_test, y_pred)\n",
    "print(\"The MSE is\", mse)\n",
    "print(\"THe RMSE is\", np.sqrt(mse))\n",
    "\n",
    "# adjusted R-Squared function to check for any feature that might blow our model out of proportion\n",
    "def adj_r2(x0,y0):\n",
    "    r2 = regressor.score(x0,y0)\n",
    "    n = x0.shape[0]\n",
    "    p = x0.shape[1]\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    return adjusted_r2\n",
    "\n",
    "#from sklearn.metrics import r2_score\n",
    "print(\"The model R2 score for training set is\", regressor.score(X_train, y_train))\n",
    "print(\"The model adjusted R2 score for training set is\", adj_r2(X_train,y_train))\n",
    "\n",
    "print(\"The model R2 score for test set is\",regressor.score(X_test, y_test))\n",
    "print(\"The model adjusted R2 score for test set is\", adj_r2(X_test,y_test))\n",
    "\n",
    "\n",
    "# print intercept and coefficients\n",
    "print(\"Model intercept is\", regressor.intercept_)\n",
    "print(\"Model coefficients are\", regressor.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our r2 score is 76.79% and adj r2 is 76.00% for our training set, so looks like we are not being penalized by use of any feature.\\\n",
    "Let's check how well model fits the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like our model r2 score is less on the test data\\\n",
    "But, through adjusted r2 score we checked and found no feature that blows our model out of proportion\\\n",
    "Let's see if our model is overfitting our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REGULARIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00037750187001649714"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso Regularization\n",
    "# LassoCV will return best alpha and coefficients after performing 10 cross validations\n",
    "from sklearn.linear_model  import Ridge,Lasso,RidgeCV, LassoCV, ElasticNet, ElasticNetCV\n",
    "lasscv = LassoCV(alphas = None,cv =10, max_iter = 100000, normalize = True)\n",
    "lasscv.fit(X_train, y_train)\n",
    "\n",
    "# best alpha parameter\n",
    "alpha = lasscv.alpha_\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 score for lasso is 0.6714069732534584\n"
     ]
    }
   ],
   "source": [
    "lasso_reg = Lasso(alpha)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "print(\"The r2 score for lasso is\", lasso_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our r2_score for test data (66.93%) comes same as before using regularization (67.14%). So, it is fair to say our Simple Linear Regression model did not overfit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14872544545650235"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Ridge regression model\n",
    "# RidgeCV will return best alpha and coefficients after performing 10 cross validations. \n",
    "# We will pass an array of random numbers for ridgeCV to select best alpha from them\n",
    "\n",
    "alphas = np.random.uniform(low=0, high=10, size=(50,))\n",
    "ridgecv = RidgeCV(alphas = alphas,cv=10,normalize = True)\n",
    "ridgecv.fit(X_train, y_train)\n",
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 score for ridge model is 0.6712629565032417\n"
     ]
    }
   ],
   "source": [
    "ridge_model = Ridge(alpha=ridgecv.alpha_)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "print(\"The r2 score for ridge model is\", ridge_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got the same r2 square using Ridge regression as well. So, it's safe to say there is no overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5508790673511257"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticCV = ElasticNetCV(alphas = None, cv =10)\n",
    "elasticCV.fit(X_train, y_train)\n",
    "elasticCV.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l1_ration gives how close the model is to L1 regularization, below value indicates we are giving equal\n",
    "#preference to L1 and L2\n",
    "elasticCV.l1_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Elastic Net CV score is 0.600320960903292\n"
     ]
    }
   ],
   "source": [
    "elasticnet_reg = ElasticNet(alpha = elasticCV.alpha_,l1_ratio=0.5)\n",
    "elasticnet_reg.fit(X_train, y_train)\n",
    "print(\"The Elastic Net CV score is\", elasticnet_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see by using different type of regularization, we still are getting the same r2 score. That means our model has been well trained over the training data and there is no overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred, color = 'red')\n",
    "plt.title('Price Actual vs Predicted ')\n",
    "plt.xlabel('Predicted Price')\n",
    "plt.ylabel('Actual Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allyson/anaconda3/envs/practice/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f581d961a10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "error = y_test - y_pred\n",
    "sns.distplot(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
